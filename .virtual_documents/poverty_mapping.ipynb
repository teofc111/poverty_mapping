# !pip install git+https://github.com/thinkingmachines/unicef-ai4d-poverty-mapping.git
# !pip install python-dotenv





import os
import re
from dotenv import load_dotenv
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from povertymapping import dhs, nightlights, feature_engineering

from sklearn.preprocessing import MinMaxScaler











# Set up for extracting relevant data from DHS
COUNTRY_CODE = "ph"                                                    # Philippines as country of interest in this study
DHS_LABEL_COL = "Wealth Index"                                         # Column name as labels for model training
OUTPUT_LABEL_COL = "Wealth Index - Scaled"
TILE_SIZE_KM = 2.4                                                     # Tile size as geographic extent for each DHS cluster (unit)

# Paths for DHS material in 2017 and 2022
DHS_HOUSEHOLD_DTA_PATH_2017 = "data/dhs/ph/PHHR71DT/PHHR71FL.DTA"      # Survey data in dta (stata) format, 2017
DHS_GEOGRAPHIC_SHP_PATH_2017 = "data/dhs/ph/PHGE71FL/PHGE71FL.shp"     # Geographic data (shapefile), 2017
DHS_HOUSEHOLD_DTA_PATH_2022 = "data/dhs/ph/PHHR82DT/PHHR82FL.DTA"      # Survey data in dta (stata) format, 2022
DHS_GEOGRAPHIC_SHP_PATH_2022 = "data/dhs/ph/PHGE81FL/PHGE81FL.shp"     # Geographic data (shapefile), 2022

# Extract DHS material, including geographic information
dhs_gdf_2017 = dhs.generate_dhs_cluster_level_data(
    DHS_HOUSEHOLD_DTA_PATH_2017,
    DHS_GEOGRAPHIC_SHP_PATH_2017,
    col_rename_config=COUNTRY_CODE,
    convert_geoms_to_bbox=True,
    bbox_size_km=TILE_SIZE_KM,
).reset_index(drop=True)

dhs_gdf_2022 = dhs.generate_dhs_cluster_level_data(
    DHS_HOUSEHOLD_DTA_PATH_2022,
    DHS_GEOGRAPHIC_SHP_PATH_2022,
    col_rename_config=COUNTRY_CODE,
    convert_geoms_to_bbox=True,
    bbox_size_km=TILE_SIZE_KM,
).reset_index(drop=True)

# Scale label column using minmax scaler, as recommended by thinkingmachines research
scaler = MinMaxScaler
country_data_2017 = dhs_gdf_2017.copy()
labels_2017 = scaler().fit_transform(country_data_2017[[DHS_LABEL_COL]])
labels_2017 = pd.DataFrame(labels_2017, columns=[OUTPUT_LABEL_COL])

country_data_2022 = dhs_gdf_2022.copy()
labels_2022 = scaler().fit_transform(country_data_2022[[DHS_LABEL_COL]])
labels_2022 = pd.DataFrame(labels_2022, columns=[OUTPUT_LABEL_COL])





dhs_gdf_2017.head()





dhs_gdf_2017.explore()





# Log-in using EOG credentials for nightlight data
env_path = Path.home() / '.env'
load_dotenv(dotenv_path=env_path)
username = os.getenv("EOG_USER")
username = username if username is not None else input("Username?")
password = os.getenv("EOG_PASSWORD", None)
password = password if password is not None else getpass.getpass("Password?")
access_token = nightlights.get_eog_access_token(username, password, save_token=True) # set save_token to True so that access token gets stored in ~/.eog_creds/eog_access_token


# Setup for constructing feature df
COUNTRY_OSM = "philippines"
OOKLA_YEAR = 2017
NIGHTLIGHTS_YEAR = 2017

# Create features dataframe using generate_features module
features_2017 = feature_engineering.generate_features(
    country_data,
    country_osm=COUNTRY_OSM,
    ookla_year=OOKLA_YEAR,
    nightlights_year=NIGHTLIGHTS_YEAR,
    scale=False,
    features_only=True,
    # use_hrsl=True,
)










1+1














# For convenience, consider the rollout version as the date of the root notebook folder.
ROLLOUT_DATE = "-".join(os.getcwd().split("/")[-2].split("-")[:3])
